{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Introduction\n",
        "\n",
        "In this homework, you will perform **Market Basket Analysis** using association rule mining and **K-Means Clustering** on two different datasets. For the Market Basket Analysis, you will parse transactional data, calculate association metrics manually for selected item pairs, and then use an automated implementation to find association rules across the dataset. This will allow you to identify patterns in purchasing behavior and understand the relationships between items in a dataset.\n",
        "\n",
        "For the K-Means Clustering section, you will cluster data points, determine the optimal number of clusters using evaluation metrics, and visualize the clusters based on key variables. By the end of this assignment, you will have gained hands-on experience in data parsing, association rule mining, clustering, and data visualization—important skills in data mining and machine learning workflows. All tasks should be completed in a Jupyter Notebook, with textual responses provided in Markdown.\n"
      ],
      "metadata": {
        "id": "1FN4caxPK9PK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aAOiHZjPQKtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset 1: Market Basket Data for Association Rule Mining\n",
        "\n",
        "The first dataset `store_data.csv` contains transactional data, where each row represents a single transaction and each item purchased is listed in a comma-separated format. Here’s an example of what a few rows look like:\n",
        "\n",
        "```\n",
        "shrimp,almonds,avocado,vegetables mix,green grapes,whole wheat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxidant juice,frozen smoothie,spinach,olive oil\n",
        "burgers,meatballs,eggs\n",
        "```\n",
        "\n",
        "To prepare this dataset for association rule mining, you will need to parse it into a format where each column represents an item, and each row indicates whether that item was purchased in the transaction. In this boolean format, a value of `True` or `1` means the item was purchased in that transaction, and `False` or `0` means it was not. This transformation will allow you to apply association rule mining techniques effectively."
      ],
      "metadata": {
        "id": "2o1_7lzRK9wS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VE0ddgjfQLjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset 2: Mine Detection Dataset\n",
        "\n",
        "In the second dataset `land_mines.csv`, magnetic anomaly data is collected from sensors, capturing factors influenced by both environmental and object-specific characteristics. The dataset includes continuous features like voltage values and sensor height, as well as categorical data representing soil and mine type. This information is used to classify the type of buried mine based on the observed anomalies.\n",
        "\n",
        "##### Data Set Columns:\n",
        "\n",
        "1. **V (Voltage):** A continuous feature representing the output voltage value of the FLC sensor due to magnetic distortion, measured in volts.\n",
        "2. **H (Height):** A continuous feature indicating the height of the sensor from the ground, measured in centimeters.\n",
        "3. **S (Soil Type):** A categorical feature representing six different soil types, which vary based on moisture conditions: `dry and sandy`, `dry and humus`, `dry and limy`, `humid and sandy`, `humid and humus`, and `humid and limy`.\n",
        "4. **M (Mine Type):** The target variable, representing five different types of mines commonly encountered on land.\n"
      ],
      "metadata": {
        "id": "Up9mVPLfBnjp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8tMBgnMEQMVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 1: Market Basket Analysis with Association Rules\n",
        "\n",
        "1. **Load the Dataset:**\n",
        "   - Use the `pandas.read_csv()` function to load the transactional dataset from the provided CSV file. Each row in this dataset represents a transaction, and each item purchased in that transaction is separated by commas.\n",
        "\n",
        "   - Print the top 5 rows of loaded dataset.\n",
        "   \n",
        "     **Hint**: Use `sep='\\t'` when loading the data to ensure all items are loaded into a single column. After that, you can parse it into boolean values with `pd.Series.str.get_dummies(sep=',')`.\n",
        "   \n",
        "     Refer to this link for more details on how to use `read_csv`: [pandas.read_csv() Documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html).\n",
        "\n",
        "2. **Parse the Data into Boolean Format:**\n",
        "   - Convert the transactional data into a boolean format suitable for association rule mining. In this format, each unique item becomes a column, and each transaction (row) is represented by `True` (1) or `False` (0) values, where:\n",
        "     - `True` indicates the item was purchased in that transaction.\n",
        "     - `False` indicates the item was not purchased in that transaction.\n",
        "   \n",
        "  - Print the top 5 rows of loaded dataset.\n",
        "\n",
        "     **Hint**: You can use the `pd.Series.str.get_dummies()` method to help transform the data or write a custom function that iterates through each row and creates a boolean representation.\n",
        "\n",
        "     Refer to this link for more details on `get_dummies`: [pandas.get_dummies() Documentation](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html).\n"
      ],
      "metadata": {
        "id": "Tbz_mA0_K9gu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NlU6PP82K8vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NM7xXHeJK8yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 1: Market Basket Analysis with Association Rules\n",
        "\n",
        "\n",
        "3. **Calculate Lift Manually for Selected Items:**\n",
        "   - Calculate  and print out the **lift** of the association rule **`ground beef -> herb & pepper`** manually:\n",
        "     - **Support for `ground beef`**: The proportion of transactions that contain `ground beef`.\n",
        "     - **Support for `herb & pepper`**: The proportion of transactions that contain `herb & pepper`.\n",
        "     - **Support for `ground beef` AND `herb & pepper`**: The proportion of transactions that contain both `ground beef` and `herb & pepper`.\n",
        "\n",
        "      **Lift Calculation**: Use the formula for lift:  \n",
        "        ```\n",
        "        Lift = Support(ground beef AND herb & pepper) / (Support(ground beef) * Support(herb & pepper))\n",
        "        ```\n",
        "\n",
        "      **Support Calculation**:\n",
        "        ```\n",
        "        Support(item) = Number of transactions containing the item / Total number of transactions\n",
        "        ```\n",
        "       **Hint**: You can use basic `pandas` operations to filter rows and count occurrences for calculating these metrics.\n",
        "\n",
        "4. **Fit the Model to Find Association Rules:**\n",
        "   - Use the `mlxtend` library to perform association rule mining on the entire dataset.\n",
        "   - Set a minimum support threshold (e.g., 0.1) and a minimum confidence threshold (e.g., 0.5) to generate association rules.\n",
        "   - Report the top 5 association rules with the highest lift values.\n",
        "\n",
        "     Refer to these links for more details:\n",
        "     - Apriori: [mlxtend apriori Documentation](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/)\n",
        "     - Association Rules: [mlxtend association_rules Documentation](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/)"
      ],
      "metadata": {
        "id": "iN9EPcztK9sg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IxmY8xbaK81P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cNhDJ286K84T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 2: K-Means Clustering\n",
        "\n",
        "1. **Load the Dataset:**\n",
        "   - Use the `pandas.read_csv()` function to load the Mine Detection dataset from the provided CSV file.\n",
        "   - Print the top 5 rows of loaded dataset.\n",
        "   \n",
        "    Refer to this link for more details on how to use `read_csv`: [pandas.read_csv() Documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html).\n",
        "\n",
        "2. **Scale the Data:**\n",
        "   - Scale the first three columns (`V`, `H`, and `S`) using standard scaling techniques to ensure that all features contribute equally to the clustering.\n",
        "   - Print the top 5 rows of scaled dataset.\n",
        "   - **Hint:** You can use `StandardScaler` from `scikit-learn` to scale the data.\n",
        "   \n",
        "    Refer to this link for more details on `StandardScaler`: [scikit-learn StandardScaler Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
        "\n",
        "\n",
        "\n",
        "3. **Determine the Best K Using the Elbow Plot:**\n",
        "   - Plot the within-cluster sum of squares (WCSS) for a range of values for `K` (e.g., from 1 to 10) to identify the \"elbow point,\" which indicates the best number of clusters.\n",
        "   \n",
        "    **Hint:** The elbow point is where the WCSS curve begins to flatten, suggesting that adding more clusters doesn’t significantly reduce the WCSS.\n",
        "\n",
        "4. **Run K-Means Clustering Using the Best K:**\n",
        "   - Use the scaled values of `V`, `H`, and `S` to perform K-Means clustering with the best `K` found in step 3.\n",
        "   - **Hint:** Use the `KMeans` class from `scikit-learn` and set `random_state=42` for consistency."
      ],
      "metadata": {
        "id": "yCa7BSgIMNbF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "doBRuHgcMNqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ln6_g8TsMNtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authentication: Write Down Your Information\n",
        "\n",
        "In the following code block, print your Student ID, Name, and Homework number in the specified format:\n",
        "\n",
        "```python\n",
        "# Replace the placeholders with your actual information\n",
        "info = [yourid, yourname, homework_number]\n",
        "for id, name, homework in info:\n",
        "    print(f'ID: {id}\\nName: {name}\\nHomework: {homework}')\n"
      ],
      "metadata": {
        "id": "EQL_0Ttl-7eE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "info = [('1001', 'Jon Doe', '001')]\n",
        "for id, name, homework in info:\n",
        "    print(f'ID: {id}\\nName: {name}\\nHomework: {homework}')"
      ],
      "metadata": {
        "id": "7gXfSXeHMNwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde51340-0475-45bc-94d2-d6a991ec47f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: 1001\n",
            "Name: Jon Doe\n",
            "Homework: 001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9mKgjDmcNZ1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ro8ThPYUNZ4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 2: K-Means Clustering\n",
        "\n",
        "\n",
        "5. **Plot Feature Pairs Against Cluster Assignments:**\n",
        "   - Use the selected `K` value to re-run K-Means clustering on `V`, `H`, and `S` and assign each data point to a cluster.\n",
        "   - Create scatter plots for the following feature pairs, using **cluster labels as the color**:\n",
        "     - **V vs. H**\n",
        "     - **H vs. S**\n",
        "     - **V vs. S**\n",
        "\n",
        "   **Hint:** You can use `matplotlib` or `seaborn` for visualization.\n",
        "\n",
        "6. **Plot Feature Pairs Against Mine Type (Target Variable M):**\n",
        "   - Create the same scatter plots (V vs. H, H vs. S, V vs. S), but this time color the points based on the **mine type (`M`)** instead of cluster labels.\n",
        "   - This will allow you to visually compare the clustering results with the actual mine types."
      ],
      "metadata": {
        "id": "rIbpkedYO438"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4JdvR0HVNZ7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9OlVBFriNZ92"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}